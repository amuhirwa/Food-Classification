{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a1a9c1c",
   "metadata": {},
   "source": [
    "# Food Classification MLOps Pipeline\n",
    "\n",
    "This notebook demonstrates an end-to-end machine learning pipeline for food image classification.\n",
    "\n",
    "## Dataset Overview\n",
    "- **Classes**: Bread, Dairy product, Dessert, Egg, Fried food, Meat, Noodles-Pasta, Rice, Seafood, Soup, Vegetable-Fruit\n",
    "- **Task**: Multi-class image classification\n",
    "- **Model**: Convolutional Neural Network with Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a420919",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0161cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2, EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8657d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick environment test\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(\"Environment is working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6416aa6c",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "DATA_DIR = '../data'\n",
    "MODEL_DIR = '../models'\n",
    "SRC_DIR = '../src'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(SRC_DIR, exist_ok=True)\n",
    "\n",
    "# Get class names\n",
    "classes = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))]\n",
    "classes.sort()\n",
    "print(f\"Number of classes: {len(classes)}\")\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "# Create class to index mapping\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}\n",
    "\n",
    "print(f\"\\nClass to index mapping:\")\n",
    "for cls, idx in class_to_idx.items():\n",
    "    print(f\"{cls}: {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a3db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze dataset distribution\n",
    "class_counts = {}\n",
    "total_images = 0\n",
    "\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(DATA_DIR, class_name)\n",
    "    image_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    class_counts[class_name] = len(image_files)\n",
    "    total_images += len(image_files)\n",
    "\n",
    "print(f\"Total images: {total_images}\")\n",
    "print(f\"\\nImages per class:\")\n",
    "for cls, count in class_counts.items():\n",
    "    print(f\"{cls}: {count}\")\n",
    "\n",
    "# Create visualization of class distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(class_counts.keys(), class_counts.values())\n",
    "plt.title('Distribution of Images per Class')\n",
    "plt.xlabel('Food Categories')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for class imbalance\n",
    "min_count = min(class_counts.values())\n",
    "max_count = max(class_counts.values())\n",
    "imbalance_ratio = max_count / min_count\n",
    "print(f\"\\nClass imbalance ratio: {imbalance_ratio:.2f} (max/min)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7f868d",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "def load_and_preprocess_data(data_dir, img_size, validation_split=0.2):\n",
    "    \"\"\"\n",
    "    Load and preprocess image data\n",
    "    \"\"\"\n",
    "    # Data augmentation for training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=validation_split\n",
    "    )\n",
    "    \n",
    "    # Only rescaling for validation data\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=validation_split\n",
    "    )\n",
    "    \n",
    "    # Create data generators\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    validation_generator = val_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=img_size,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator\n",
    "\n",
    "# Load data\n",
    "train_gen, val_gen = load_and_preprocess_data(DATA_DIR, IMG_SIZE, VALIDATION_SPLIT)\n",
    "\n",
    "print(f\"Training samples: {train_gen.samples}\")\n",
    "print(f\"Validation samples: {val_gen.samples}\")\n",
    "print(f\"Number of classes: {train_gen.num_classes}\")\n",
    "print(f\"Class indices: {train_gen.class_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b89565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from each class\n",
    "def visualize_samples(data_dir, classes, num_samples=3):\n",
    "    \"\"\"\n",
    "    Visualize sample images from each class\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(len(classes), num_samples, figsize=(15, 20))\n",
    "    \n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        image_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        for j in range(min(num_samples, len(image_files))):\n",
    "            img_path = os.path.join(class_path, image_files[j])\n",
    "            img = load_img(img_path, target_size=IMG_SIZE)\n",
    "            \n",
    "            if len(classes) == 1:\n",
    "                axes[j].imshow(img)\n",
    "                axes[j].set_title(f\"{class_name}\")\n",
    "                axes[j].axis('off')\n",
    "            else:\n",
    "                axes[i, j].imshow(img)\n",
    "                if j == 0:\n",
    "                    axes[i, j].set_ylabel(class_name, fontsize=12)\n",
    "                axes[i, j].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Images from Each Class', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples(DATA_DIR, classes, num_samples=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b672a036",
   "metadata": {},
   "source": [
    "## 4. Model Creation with Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3f14c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes, input_shape=(224, 224, 3), base_model_name='MobileNetV2'):\n",
    "    \"\"\"\n",
    "    Create a CNN model with transfer learning\n",
    "    \"\"\"\n",
    "    # Load pre-trained base model\n",
    "    if base_model_name == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    elif base_model_name == 'EfficientNetB0':\n",
    "        base_model = EfficientNetB0(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    \n",
    "    # Freeze base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom classification head\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_model(num_classes=len(classes), base_model_name='MobileNetV2')\n",
    "\n",
    "# Compile model with optimization techniques\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7589aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for optimization\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=os.path.join(MODEL_DIR, 'best_food_classifier.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Model compilation completed. Ready for training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20762120",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0cf41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "EPOCHS = 50\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c21d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation metrics\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 0].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    axes[0, 0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    axes[0, 0].set_title('Model Accuracy')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 1].plot(history.history['loss'], label='Training Loss')\n",
    "    axes[0, 1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "    axes[0, 1].set_title('Model Loss')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Precision\n",
    "    axes[1, 0].plot(history.history['precision'], label='Training Precision')\n",
    "    axes[1, 0].plot(history.history['val_precision'], label='Validation Precision')\n",
    "    axes[1, 0].set_title('Model Precision')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Recall\n",
    "    axes[1, 1].plot(history.history['recall'], label='Training Recall')\n",
    "    axes[1, 1].plot(history.history['val_recall'], label='Validation Recall')\n",
    "    axes[1, 1].set_title('Model Recall')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1133738b",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model = tf.keras.models.load_model(os.path.join(MODEL_DIR, 'best_food_classifier.h5'))\n",
    "\n",
    "# Make predictions on validation data\n",
    "val_gen.reset()\n",
    "predictions = best_model.predict(val_gen, verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "true_classes = val_gen.classes\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "print(\"=== Model Evaluation Metrics ===\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\n=== Detailed Classification Report ===\")\n",
    "class_names = list(val_gen.class_indices.keys())\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd58a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "print(\"\\n=== Per-Class Accuracy ===\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"{class_name}: {per_class_accuracy[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92418629",
   "metadata": {},
   "source": [
    "## 7. Model Interpretability and Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2560f211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model predictions on sample images\n",
    "def analyze_predictions(model, data_dir, classes, num_samples=5):\n",
    "    \"\"\"\n",
    "    Analyze model predictions with confidence scores\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(len(classes), num_samples, figsize=(20, 25))\n",
    "    \n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        image_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        for j in range(min(num_samples, len(image_files))):\n",
    "            img_path = os.path.join(class_path, image_files[j])\n",
    "            \n",
    "            # Load and preprocess image\n",
    "            img = load_img(img_path, target_size=IMG_SIZE)\n",
    "            img_array = img_to_array(img) / 255.0\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "            \n",
    "            # Make prediction\n",
    "            prediction = model.predict(img_array, verbose=0)\n",
    "            predicted_class_idx = np.argmax(prediction)\n",
    "            confidence = np.max(prediction)\n",
    "            predicted_class = classes[predicted_class_idx]\n",
    "            \n",
    "            # Determine if prediction is correct\n",
    "            is_correct = predicted_class == class_name\n",
    "            color = 'green' if is_correct else 'red'\n",
    "            \n",
    "            # Plot image with prediction\n",
    "            if len(classes) == 1:\n",
    "                axes[j].imshow(img)\n",
    "                axes[j].set_title(f\"True: {class_name}\\nPred: {predicted_class}\\nConf: {confidence:.3f}\", \n",
    "                                color=color)\n",
    "                axes[j].axis('off')\n",
    "            else:\n",
    "                axes[i, j].imshow(img)\n",
    "                axes[i, j].set_title(f\"True: {class_name}\\nPred: {predicted_class}\\nConf: {confidence:.3f}\", \n",
    "                                    color=color, fontsize=8)\n",
    "                axes[i, j].axis('off')\n",
    "                if j == 0:\n",
    "                    axes[i, j].set_ylabel(class_name, fontsize=10)\n",
    "    \n",
    "    plt.suptitle('Model Predictions Analysis (Green=Correct, Red=Incorrect)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_predictions(best_model, DATA_DIR, classes, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ee824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence distribution analysis\n",
    "all_predictions = []\n",
    "all_confidences = []\n",
    "all_true_labels = []\n",
    "\n",
    "for class_idx, class_name in enumerate(classes):\n",
    "    class_path = os.path.join(DATA_DIR, class_name)\n",
    "    image_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for img_file in image_files[:50]:  # Sample 50 images per class\n",
    "        img_path = os.path.join(class_path, img_file)\n",
    "        \n",
    "        # Load and preprocess image\n",
    "        img = load_img(img_path, target_size=IMG_SIZE)\n",
    "        img_array = img_to_array(img) / 255.0\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = best_model.predict(img_array, verbose=0)\n",
    "        confidence = np.max(prediction)\n",
    "        predicted_class_idx = np.argmax(prediction)\n",
    "        \n",
    "        all_predictions.append(predicted_class_idx)\n",
    "        all_confidences.append(confidence)\n",
    "        all_true_labels.append(class_idx)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_confidences = np.array(all_confidences)\n",
    "all_true_labels = np.array(all_true_labels)\n",
    "\n",
    "# Plot confidence distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(all_confidences, bins=30, alpha=0.7, edgecolor='black')\n",
    "plt.title('Distribution of Prediction Confidences')\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "correct_predictions = all_predictions == all_true_labels\n",
    "correct_confidences = all_confidences[correct_predictions]\n",
    "incorrect_confidences = all_confidences[~correct_predictions]\n",
    "\n",
    "plt.hist(correct_confidences, bins=20, alpha=0.7, label='Correct', color='green')\n",
    "plt.hist(incorrect_confidences, bins=20, alpha=0.7, label='Incorrect', color='red')\n",
    "plt.title('Confidence: Correct vs Incorrect Predictions')\n",
    "plt.xlabel('Confidence Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "class_accuracies = []\n",
    "for i in range(len(classes)):\n",
    "    class_mask = all_true_labels == i\n",
    "    class_accuracy = np.mean(all_predictions[class_mask] == all_true_labels[class_mask])\n",
    "    class_accuracies.append(class_accuracy)\n",
    "\n",
    "plt.bar(range(len(classes)), class_accuracies)\n",
    "plt.title('Per-Class Accuracy')\n",
    "plt.xlabel('Class Index')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(range(len(classes)), [f'{i}\\n{classes[i][:8]}' for i in range(len(classes))], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOverall accuracy on sample: {np.mean(all_predictions == all_true_labels):.4f}\")\n",
    "print(f\"Average confidence: {np.mean(all_confidences):.4f}\")\n",
    "print(f\"Average confidence for correct predictions: {np.mean(correct_confidences):.4f}\")\n",
    "print(f\"Average confidence for incorrect predictions: {np.mean(incorrect_confidences):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5a97b",
   "metadata": {},
   "source": [
    "## 8. Save Model and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50fdb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "final_model_path = os.path.join(MODEL_DIR, 'food_classifier_final.h5')\n",
    "best_model.save(final_model_path)\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_name': 'Food Classification CNN',\n",
    "    'created_date': datetime.now().isoformat(),\n",
    "    'classes': classes,\n",
    "    'class_to_idx': class_to_idx,\n",
    "    'idx_to_class': idx_to_class,\n",
    "    'num_classes': len(classes),\n",
    "    'input_shape': IMG_SIZE + (3,),\n",
    "    'metrics': {\n",
    "        'accuracy': float(accuracy),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'f1_score': float(f1)\n",
    "    },\n",
    "    'training_params': {\n",
    "        'epochs': EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'validation_split': VALIDATION_SPLIT,\n",
    "        'base_model': 'MobileNetV2'\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(MODEL_DIR, 'model_metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "# Save class mappings separately for easy access\n",
    "joblib.dump(class_to_idx, os.path.join(MODEL_DIR, 'class_to_idx.pkl'))\n",
    "joblib.dump(idx_to_class, os.path.join(MODEL_DIR, 'idx_to_class.pkl'))\n",
    "\n",
    "print(f\"Model saved to: {final_model_path}\")\n",
    "print(f\"Metadata saved to: {metadata_path}\")\n",
    "print(f\"Class mappings saved to: {MODEL_DIR}\")\n",
    "\n",
    "print(\"\\n=== Training Complete ===\")\n",
    "print(f\"Final Model Performance:\")\n",
    "print(f\"  - Accuracy: {accuracy:.4f}\")\n",
    "print(f\"  - Precision: {precision:.4f}\")\n",
    "print(f\"  - Recall: {recall:.4f}\")\n",
    "print(f\"  - F1-Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
